https://visualgo.net/en/sorting

=======>
a1.
Bubble Sort
    Bubble Sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order.
    It keeps "bubbling" the largest value to the end in each pass â€” like bubbles rising in water ðŸ’§.

    How ?
    * Compare two adjacent elements.
    * Swap if the left is greater than the right.
    * Repeat until the array is sorted.

Algorithm 
    1. Start from the beginning of the array.
    2. Compare the current element with the next element.
    3. If the current element is greater than the next one, swap them.
    4. Move to the next pair of elements and repeat Step 2â€“3.
    5. After one full pass, the largest element will be at the end of the array.
    6. Repeat the above steps for the remaining (unsorted) portion of the array.
    7. Stop when no swaps are needed in a full pass (i.e., array is sorted).

Time Complexity
    Case    | Time
    Best    | O(n) (Already sorted)
    Average | O(nÂ²)
    Worst   | O(nÂ²)
    Space   | O(1)
<=======

=======>
a2.
Insertion Sort
    Insertion Sort builds the final sorted array one item at a time. Itâ€™s similar to how you might sort playing cards in your hand.

    How ?
    * Start from the second element (index 1).
    * Compare it with the elements before.
    * Shift all greater elements one position to the right.
    * Insert the current element in the correct position.

Time Complexity
    Case    | Time
    Best    | O(n) (alreay sorted)
    Average | O(nÂ²)
    Worst   | O(nÂ²)
    Space   | O(1)
<=======

=======>
a3.
Selection Sort
    Selection Sort is a simple comparison-based sorting algorithm.
    It works by repeatedly finding the minimum element from the unsorted part and putting it at the beginning.

    Why ?
    Easy to understand and implement.
    Good for small datasets.
    Does not require extra memory (in-place sorting).
    Not the most efficient for large arrays

    Time Complexity -(nÂ²) - for best, average, and worst
    space complexity - O(1) - no extra space used
    When to Use -- 	For small data or learning purposes
<=======

=======>
a4.
Merge Sort
    Merge Sort is a divide and conquer algorithm that:
    1. Divides the array into halves,
    2. Sorts each half recursively,
    3. Merges the sorted halves back together.

    Why ?
    Very efficient for large datasets.
    Stable sort (maintains order of equal elements).
    Consistent O(n log n) time complexity.
<=======

=======>
a5.
Quick Sort
    Quick Sort is a Divide & Conquer algorithm.
    It selects a pivot, partitions the array around it, and recursively sorts the sub-arrays.

    Why ?
    Efficient for large datasets
    Average Time: O(n log n)
    Worst-case: O(nÂ²) (rare, can be avoided with random pivots)
    In-place and fast in practice
<=======

=======>
a6.
Linear Search
    Linear Search is the simplest search algorithm.
    It checks each element one by one until the desired value is found or the array ends.

    Why ?
    Best for small datasets
    No sorting required
    Works on unsorted arrays
    Very easy to implement

    Summary 
    Feature         | Detail
    Type            | Search Algorithm
    Time Complexity | O(n)
    Space           | O(1)
    When to use     | Small or unsorted arrays
    Stable          | âœ… Yes
    Simple          | âœ… Very Easy
<=======

=======>
a7.
Binary Search
    Binary Search is an efficient algorithm to find an element in a sorted 
    array by repeatedly dividing the search space in half.

    Why ?
    Much faster than Linear Search for large, sorted arrays
    Time Complexity: O(log n)
    Requires the array to be sorted

    Summary 
    Feature         | Detail
    Type            | Search Algorithm
    Time Complexity | O(log n)
    Space           | O(1)
    Sorted Required | âœ… Yes
    Faster than     | Linear Search on large datasets
<=======

=======>
a8.
Recursion
    Recursion is a technique where a function calls itself to solve smaller instances of a problem.

    Why ?
    To break down complex problems into simpler ones
    Useful for problems like tree traversal, factorial, fibonacci, etc.
    Makes code cleaner and shorter in some cases

    How ?
    A recursive function has:
    Base Case â€“ when to stop recursion
    Recursive Case â€“ when the function calls itself

    Summary 
    Concept               | Description
    Function calls itself | âœ… Yes
    Base case needed      | âœ… To stop recursion
    Useful for            | Tree, graphs, math problems
    Risk                  | Stack overflow (if not handled well)
<=======